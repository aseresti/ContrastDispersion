{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Velocity Based on Contrast Dispersion in Grafts\n",
    "\n",
    " - Extract the graft from the peak intensity image on SimVascular:\n",
    "\n",
    "        Extract .pth of the manual annotation and .vtu of the mesh\n",
    "\n",
    " - Register the CT-MPI sequence if needed.\n",
    " - Project the Image values onto the mesh.\n",
    " - Convert pathline to vtp and project image onto the pathline.\n",
    " - Use a gradient filter and argmax to find the point of shuttle mode on the pathline.\n",
    " - Clip the lumen at the point where the shuttle mode causes inconsistency.\n",
    " - Take a cross-sectional sample every 5 mm along the lumen.\n",
    " - Extract the TAC on every point.\n",
    " - Detect the upslope. (?)\n",
    " - Interpolate each point.\n",
    " - Concatenate upper and lower parts of the lumen at the same time points.\n",
    " - Extract temporal and spatial gradient.\n",
    " - Extract the velocity.\n",
    " - Baysian Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vtk\n",
    "import glob as glob_module\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "from scipy.stats import linregress\n",
    "from scipy.integrate import odeint\n",
    "from scipy.interpolate import CubicSpline, interp1d\n",
    "import matplotlib.cm as cm\n",
    "from vtk.util.numpy_support import vtk_to_numpy, numpy_to_vtk\n",
    "from utilities import *\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['mathtext.fontset'] = 'custom'\n",
    "plt.rcParams['mathtext.rm'] = 'Times New Roman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ = \"/Users/ana/Documents/AnahitaSeresti/06_ContrastDispersion/3_VesselProjection/VA02B/SVG_RCA\"\n",
    "graft_name = \"SVG_RCA\"\n",
    "vtu_file_ = os.path.join(path_,f\"{graft_name}.vtu\")\n",
    "centerline_file_ = os.path.join(path_, f\"{graft_name}.pth\")\n",
    "Image_directory_ = \"/Users/ana/Documents/AnahitaSeresti/06_ContrastDispersion/1_CTPImages/VA02B/CTP\"\n",
    "Image_names = sorted(glob_module.glob(f\"{Image_directory_}/*.vtk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Images to the Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProbeFilter(TargetData, SourceData):\n",
    "    ProbeFilter=vtk.vtkProbeFilter()\n",
    "    ProbeFilter.SetInputData(TargetData)\n",
    "    ProbeFilter.SetSourceData(SourceData)\n",
    "    ProbeFilter.Update()\n",
    "    \n",
    "    return ProbeFilter.GetOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.splitext(os.path.basename(Image_names[0]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mesh = ReadVTUFile(vtu_file_)\n",
    "MeshProjections = {}\n",
    "for image_name in Image_names:\n",
    "    Image_ = ReadVTKFile(image_name)\n",
    "    mesh_projection = ProbeFilter(Mesh, Image_)\n",
    "    image_root_name = os.path.splitext(os.path.basename(image_name))[0]\n",
    "    mesh_name = f\"{graft_name}_{image_root_name}\"\n",
    "    MeshProjections[image_root_name] = mesh_projection\n",
    "    WriteVTUFile(os.path.join(path_,f\"{mesh_name}.vtu\"), mesh_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MeshProjections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read SimVascular Pathline Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(centerline_file_, \"r\") as path:\n",
    "    #path.readlines()\n",
    "    tree = ET.parse(path)\n",
    "root = tree.getroot()\n",
    "\n",
    "direction_points = []\n",
    "for direction_point in root.findall(\".//path_point/tangent\"):\n",
    "    x = float(direction_point.attrib['x'])\n",
    "    y = float(direction_point.attrib['y'])\n",
    "    z = float(direction_point.attrib['z'])\n",
    "    direction_points.append((x,y,z))\n",
    "\n",
    "position_points = []\n",
    "for path_point in root.findall(\".//path_point/pos\"):\n",
    "    x = float(path_point.attrib['x'])\n",
    "    y = float(path_point.attrib['y'])\n",
    "    z = float(path_point.attrib['z'])\n",
    "    position_points.append((x,y,z))\n",
    "\n",
    "path_normals = []\n",
    "for normal in root.findall(\".//path_point/rotation\"):\n",
    "    x = float(normal.attrib['x'])\n",
    "    y = float(normal.attrib['y'])\n",
    "    z = float(normal.attrib['z'])\n",
    "    path_normals.append((x,y,z))\n",
    "\n",
    "NPoints = len(position_points)\n",
    "print(\"the number of points in the centerline is:\", NPoints)\n",
    "\n",
    "binormal = []\n",
    "for i in range(NPoints):\n",
    "    binormal_ = np.cross(np.array(direction_points[i]),np.array(path_normals[i]))\n",
    "    binormal_ /= np.linalg.norm(binormal_)\n",
    "    binormal.append(binormal_)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation of the pathline\n",
    "\n",
    "Need to interpolate the pathline to get equi-distance points.\n",
    "\n",
    "pipeline: \n",
    " - use a cubic spline with a fine resolution. (10000 points).\n",
    " - undersample it to get points every 0.5 or 1 mm. Depending on the spacing.\n",
    "\n",
    " or:\n",
    " - interpolate on x, y, and z separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_distance = [0]\n",
    "for i in range(1, NPoints):\n",
    "    dist_ = np.sqrt((position_points[i][0] - position_points[i-1][0])**2 +\n",
    "                    (position_points[i][1] - position_points[i-1][1])**2 +\n",
    "                    (position_points[i][2] - position_points[i-1][2])**2 )\n",
    "    cumulative_distance.append(dist_ + cumulative_distance[i-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolating on x, y, and z separately\n",
    "\n",
    "spacing = 1 #mm\n",
    "new_distances = [i + spacing for i in range(int(max(cumulative_distance)))]\n",
    "\n",
    "#>>> interpolating the position points\n",
    "x = np.zeros(len(position_points))\n",
    "y = np.zeros(len(position_points))\n",
    "z = np.zeros(len(position_points))\n",
    "\n",
    "for i, point in enumerate(position_points):\n",
    "    (x_, y_, z_) = point\n",
    "    x[i] = point[0]\n",
    "    y[i] = point[1]\n",
    "    z[i] = point[2]\n",
    "\n",
    "f_cubic_x = interp1d(cumulative_distance, x, kind=\"cubic\")\n",
    "f_cubic_y = interp1d(cumulative_distance, y, kind=\"cubic\")\n",
    "f_cubic_z = interp1d(cumulative_distance, z, kind=\"cubic\")\n",
    "\n",
    "x_interp = f_cubic_x(new_distances)\n",
    "y_interp = f_cubic_y(new_distances)\n",
    "z_interp = f_cubic_z(new_distances)\n",
    "\n",
    "\n",
    "new_position_points = []\n",
    "for i in range(len(new_distances)):\n",
    "    new_position_points.append((x_interp[i], y_interp[i], z_interp[i]))\n",
    "\n",
    "\n",
    "#>>> interolating the direction points\n",
    "x = np.zeros(len(direction_points))\n",
    "y = np.zeros(len(direction_points))\n",
    "z = np.zeros(len(direction_points))\n",
    "\n",
    "\n",
    "for i, point in enumerate(direction_points):\n",
    "    (x_, y_, z_) = point\n",
    "    x[i] = point[0]\n",
    "    y[i] = point[1]\n",
    "    z[i] = point[2]\n",
    "\n",
    "f_cubic_x = interp1d(cumulative_distance, x, kind=\"cubic\")\n",
    "f_cubic_y = interp1d(cumulative_distance, y, kind=\"cubic\")\n",
    "f_cubic_z = interp1d(cumulative_distance, z, kind=\"cubic\")\n",
    "\n",
    "x_interp = f_cubic_x(new_distances)\n",
    "y_interp = f_cubic_y(new_distances)\n",
    "z_interp = f_cubic_z(new_distances)\n",
    "\n",
    "\n",
    "new_direction_points = []\n",
    "for i in range(len(new_distances)):\n",
    "    new_direction_points.append((x_interp[i], y_interp[i], z_interp[i]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Pathline to VTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_to_vtp(points):\n",
    "    # Create VTK points\n",
    "    vtk_points = vtk.vtkPoints()\n",
    "    for point in points:\n",
    "        vtk_points.InsertNextPoint(point)\n",
    "\n",
    "    # Create a polyline\n",
    "    polyline = vtk.vtkPolyLine()\n",
    "    polyline.GetPointIds().SetNumberOfIds(len(points))\n",
    "    for i in range(len(points)):\n",
    "        polyline.GetPointIds().SetId(i, i)\n",
    "\n",
    "    # Create a cell array to store the polyline\n",
    "    cells = vtk.vtkCellArray()\n",
    "    cells.InsertNextCell(polyline)\n",
    "\n",
    "    # Create a polydata object\n",
    "    polydata = vtk.vtkPolyData()\n",
    "    polydata.SetPoints(vtk_points)\n",
    "    polydata.SetLines(cells)\n",
    "\n",
    "    return polydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centerline_vtp = points_to_vtp(position_points)\n",
    "new_centerline_vtp = points_to_vtp(new_position_points)\n",
    "WriteVTPFile(os.path.join(path_, \"new_centerline.vtp\"), new_centerline_vtp)\n",
    "peak_intensity = 5\n",
    "image_ = ReadVTKFile(Image_names[peak_intensity])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the vessel to the upper and lower segments\n",
    "splitting into two halves along the z-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_filter(vtk_image):\n",
    "    gradient_filter = vtk.vtkImageGradient()\n",
    "    gradient_filter.SetInputData(vtk_image)\n",
    "    gradient_filter.SetDimensionality(3)\n",
    "    gradient_filter.Update()\n",
    "\n",
    "    return gradient_filter.GetOutput()\n",
    "    \n",
    "def define_borders(gradient_image):\n",
    "    magnitude_filter = vtk.vtkImageMagnitude()\n",
    "    magnitude_filter.SetInputData(gradient_image)\n",
    "    magnitude_filter.Update()\n",
    "    \n",
    "    return magnitude_filter.GetOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_polydata_with_plane(polydata, origin, normal, inside_out=False):\n",
    "    plane = vtk.vtkPlane()\n",
    "    plane.SetOrigin(origin)\n",
    "    plane.SetNormal(normal)\n",
    "\n",
    "    clipper = vtk.vtkClipPolyData()\n",
    "    clipper.SetInputData(polydata)\n",
    "    clipper.SetClipFunction(plane)\n",
    "\n",
    "    if inside_out:\n",
    "        clipper.InsideOutOn()\n",
    "    else:\n",
    "        clipper.InsideOutOff()\n",
    "    \n",
    "    clipper.Update()\n",
    "\n",
    "    return clipper.GetOutput()\n",
    "\n",
    "def clip_USGrid_w_plane(USGrid, origin, normal, inside_out = False):\n",
    "    plane = vtk.vtkPlane()\n",
    "    plane.SetOrigin(origin)\n",
    "    plane.SetNormal(normal)\n",
    "\n",
    "    clipper = vtk.vtkClipDataSet()\n",
    "    clipper.SetInputData(USGrid)\n",
    "    clipper.SetClipFunction(plane)\n",
    "\n",
    "    if inside_out:\n",
    "        clipper.InsideOutOn()\n",
    "    else:\n",
    "        clipper.InsideOutOff()\n",
    "    \n",
    "    clipper.Update()\n",
    "\n",
    "    return clipper.GetOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = image_.GetBounds()[0]\n",
    "x_max = image_.GetBounds()[1]\n",
    "\n",
    "y_min = image_.GetBounds()[2]\n",
    "y_max = image_.GetBounds()[3]\n",
    "\n",
    "z_min = image_.GetBounds()[4]\n",
    "z_max = image_.GetBounds()[5]\n",
    "\n",
    "center_point = [\n",
    "    (x_max + x_min)/2,\n",
    "    (y_max + y_min)/2,\n",
    "    (z_max + z_min)/2\n",
    "]\n",
    "z_axis = [0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UpperMesh = {}\n",
    "LowerMesh = {}\n",
    "\n",
    "for key, mesh in MeshProjections.items():\n",
    "    upper_mesh = clip_USGrid_w_plane(mesh, center_point, z_axis, True)\n",
    "    mesh_name_upper = f\"{graft_name}_{key}_upper\"\n",
    "    if upper_mesh.GetNumberOfPoints() == 0:\n",
    "        UpperMesh[key] = upper_mesh\n",
    "        WriteVTUFile(os.path.join(path_,f\"{mesh_name_upper}.vtu\"), upper_mesh)\n",
    "    \n",
    "    lower_mesh = clip_USGrid_w_plane(mesh, center_point, z_axis)\n",
    "    mesh_name_lower = f\"{graft_name}_{key}_lower\"\n",
    "    if lower_mesh.GetNumberOfPoints() == 0:\n",
    "        LowerMesh[key] = lower_mesh\n",
    "        WriteVTUFile(os.path.join(path_,f\"{mesh_name_lower}.vtu\"), lower_mesh)\n",
    "\n",
    "\n",
    "centerline_upper = clip_polydata_with_plane(new_centerline_vtp, center_point, z_axis, True)\n",
    "centerline_lower = clip_polydata_with_plane(new_centerline_vtp, center_point, z_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting the lumen at each cenreline point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_w_plane(Volume,Origin,Norm):\n",
    "    plane=vtk.vtkPlane()\n",
    "    plane.SetOrigin(Origin)\n",
    "    plane.SetNormal(Norm)\n",
    "    Slice=vtk.vtkCutter()\n",
    "    Slice.GenerateTrianglesOff()\n",
    "    Slice.SetCutFunction(plane)\n",
    "    Slice.SetInputData(Volume)\n",
    "    Slice.Update()\n",
    "    return Slice.GetOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SphereClip(volume_image,center,radius):\n",
    "    sphere = vtk.vtkSphere()\n",
    "    sphere.SetCenter(center)\n",
    "    sphere.SetRadius(radius)\n",
    "\n",
    "    clipper = vtk.vtkClipDataSet()\n",
    "    clipper.SetInputData(volume_image)\n",
    "    clipper.SetClipFunction(sphere)\n",
    "    clipper.InsideOutOn()\n",
    "    clipper.GetOutputInformation(1)\n",
    "    clipper.Update()\n",
    "\n",
    "    return clipper.GetOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSurfaceArea(polydata):\n",
    "    properties = vtk.vtkMassProperties()\n",
    "    properties.AddInputData(polydata)\n",
    "    properties.Update()\n",
    "    return properties.GetSurfaceArea()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CrossSections = vtk.vtkAppendPolyData()\n",
    "Area_ = [] \n",
    "for idx in range(len(new_position_points)):\n",
    "    cross_section_ = slice_w_plane(MeshProjections['VA02B_06'], new_position_points[idx], new_direction_points[idx])\n",
    "    area_ = GetSurfaceArea(cross_section_)\n",
    "    Area_.append(area_)\n",
    "    radius = np.sqrt(area_/np.pi)\n",
    "    inner_section_ = SphereClip(cross_section_, GetCentroid(cross_section_), radius*0.75)\n",
    "    CrossSections.AddInputData(ExtractSurface(inner_section_))\n",
    "CrossSections.Update()\n",
    "Area = np.mean(np.array(Area_))\n",
    "WriteVTPFile(os.path.join(path_, \"CrossSections.vtp\"), CrossSections.GetOutput())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting cross sections from upper and lower parts of the lumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting which half is leading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScalarArrayName = image_.GetPointData().GetArrayName(0)\n",
    "print(ScalarArrayName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leading = False #if True upper half is leading\n",
    "upper_mean_ = []\n",
    "lower_mean_ = []\n",
    "for name in Image_names:\n",
    "    Image_ = ReadVTKFile(name)\n",
    "    centerline_ = ProbeFilter(centerline_vtp, Image_)\n",
    "    WriteVTPFile(os.path.join(path_, \"test_centerline.vtp\"), centerline_)\n",
    "    centerline_upper_ = clip_polydata_with_plane(centerline_, center_point, z_axis, True)\n",
    "    WriteVTPFile(os.path.join(path_, \"test_centerline_upper.vtp\"), centerline_upper_)\n",
    "    centerline_lower_ = clip_polydata_with_plane(centerline_, center_point, z_axis)\n",
    "    WriteVTPFile(os.path.join(path_, \"test_centerline_lower.vtp\"), centerline_lower_)\n",
    "    for i in range(Image_.GetPointData().GetNumberOfArrays()):\n",
    "        arrayname_ = Image_.GetPointData().GetArrayName(i)\n",
    "        if \"scalar\" in arrayname_.lower():\n",
    "            ScalarArrayName = arrayname_\n",
    "    upper_mean_.append(np.mean(vtk_to_numpy(centerline_upper_.GetPointData().GetArray(ScalarArrayName))))\n",
    "    lower_mean_.append(np.mean(vtk_to_numpy(centerline_lower_.GetPointData().GetArray(ScalarArrayName))))\n",
    "\n",
    "count = [i for i in range(len(Image_names))]\n",
    "plt.figure()\n",
    "plt.plot(count, upper_mean_, label = \"Upper Mean\")\n",
    "plt.plot(count, lower_mean_, label = \"Lower Mean\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "max_lower_idx = np.where(np.array(lower_mean_) == max(lower_mean_))\n",
    "max_upper_idx = np.where(np.array(upper_mean_) == max(upper_mean_))\n",
    "if max_lower_idx > max_upper_idx:\n",
    "    leading = True\n",
    "    print(\"The upper half leads the lower half.\")\n",
    "else:\n",
    "    leading = False\n",
    "    print(\"The upper half lags the lower half.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the cross sections along the upper part of the lumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPoints(polydata):\n",
    "    \"\"\"Converts the polydata into a list of points.\n",
    "    \"\"\"\n",
    "    NPoints = polydata.GetNumberOfPoints()\n",
    "    points = []\n",
    "    for i in range(NPoints):\n",
    "        points.append(polydata.GetPoint(i))\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: \n",
    "\n",
    "~~add another loop that loops over the Upper/Lower meshes.~~\n",
    "\n",
    "~~create an array of means of each cross section over time.~~\n",
    "\n",
    "~~interpolate the array (piecewise interpolation).~~\n",
    "\n",
    "~~remove the first and last elements of each array based on upper half leading or lagging.~~\n",
    "\n",
    "~~concatenate the arrays.~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two cells are for test purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centerline_upper_points = GetPoints(centerline_upper)\n",
    "\n",
    "CrossSections_u = vtk.vtkAppendPolyData()\n",
    "for idx in range(len(centerline_upper_points)):\n",
    "    cross_section_ = slice_w_plane(UpperMesh[list(UpperMesh.keys())[peak_intensity]], position_points[idx], direction_points[idx])\n",
    "    radius = np.sqrt(GetSurfaceArea(cross_section_)/np.pi)\n",
    "    inner_section_ = SphereClip(cross_section_, GetCentroid(cross_section_), radius*0.75)\n",
    "    CrossSections_u.AddInputData(ExtractSurface(inner_section_))\n",
    "CrossSections_u.Update()\n",
    "WriteVTPFile(os.path.join(path_, \"CrossSections_Upper.vtp\"), CrossSections_u.GetOutput())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centerline_lower_points = GetPoints(centerline_lower)\n",
    "indeces_l = SequentialCut(centerline_lower_points, 2)\n",
    "CrossSections_l = vtk.vtkAppendPolyData()\n",
    "for idx in indeces_l:\n",
    "    cross_section_ = slice_w_plane(LowerMesh[list(UpperMesh.keys())[peak_intensity]], position_points[len(centerline_upper_points) + idx], direction_points[len(centerline_upper_points) + idx])\n",
    "    radius = np.sqrt(GetSurfaceArea(cross_section_)/np.pi)\n",
    "    inner_section_ = SphereClip(cross_section_, GetCentroid(cross_section_), radius*0.75)\n",
    "    CrossSections_l.AddInputData(ExtractSurface(inner_section_))\n",
    "CrossSections_l.Update()\n",
    "WriteVTPFile(os.path.join(path_, \"CrossSections_Lower.vtp\"), CrossSections_l.GetOutput())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looping over all of the meshes and extracting a mean array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centerline_upper_points = GetPoints(centerline_upper)\n",
    "indeces_u = SequentialCut(centerline_upper_points, 2)\n",
    "\n",
    "UpperMeanArrays = {}\n",
    "for idx in indeces_u:\n",
    "    cross_section_mean_array = []\n",
    "    for key, mesh in UpperMesh.items():\n",
    "        cross_section_ = slice_w_plane(mesh, position_points[idx], direction_points[idx])\n",
    "        radius = np.sqrt(GetSurfaceArea(cross_section_)/np.pi)\n",
    "        inner_section_ = SphereClip(cross_section_, GetCentroid(cross_section_), radius*0.75)\n",
    "        for i in range(inner_section_.GetPointData().GetNumberOfArrays()):\n",
    "            arrayname_ = inner_section_.GetPointData().GetArrayName(i)\n",
    "            if \"scalar\" in arrayname_.lower():\n",
    "                ScalarArrayName = arrayname_\n",
    "        cross_section_mean_array.append(np.mean(vtk_to_numpy(inner_section_.GetPointData().GetArray(ScalarArrayName))))\n",
    "    \n",
    "    # add interpolation— then remove the element based on leading/lagging and store it in the dict\n",
    "    tac = np.empty(2*len(cross_section_mean_array) - 1)\n",
    "    for i in range(len(cross_section_mean_array) - 1):\n",
    "        tac[2*i] = cross_section_mean_array[i]\n",
    "        tac[2*i+1] = (cross_section_mean_array[i] + cross_section_mean_array[i+1])/2\n",
    "    \n",
    "    tac[-1] = cross_section_mean_array[-1]\n",
    "\n",
    "    UpperMeanArrays[cumulative_distance[idx]] = tac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [i for i in range(len(tac) - 1)]\n",
    "plt.figure()\n",
    "plt.scatter(count, UpperMeanArrays[list(UpperMeanArrays.keys())[-1]],marker = 'o', s = 100, label = \"Interpolation Results\")\n",
    "count = [i for i in range(len(tac)) if i%2 == 0]\n",
    "plt.scatter(count, cross_section_mean_array, marker = 'D', s = 30, label = \"Actual Data\")\n",
    "plt.legend(loc= \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centerline_lower_points = GetPoints(centerline_lower)\n",
    "indeces_l = SequentialCut(centerline_lower_points, 2)\n",
    "\n",
    "LowerMeanArrays = {}\n",
    "for idx in indeces_l:\n",
    "    cross_section_mean_array = []\n",
    "    for key, mesh in LowerMesh.items():\n",
    "        cross_section_ = slice_w_plane(mesh, position_points[len(centerline_upper_points) + idx], direction_points[len(centerline_upper_points) + idx])\n",
    "        radius = np.sqrt(GetSurfaceArea(cross_section_)/np.pi)\n",
    "        inner_section_ = SphereClip(cross_section_, GetCentroid(cross_section_), radius*0.75)\n",
    "        for i in range(inner_section_.GetPointData().GetNumberOfArrays()):\n",
    "            arrayname_ = inner_section_.GetPointData().GetArrayName(i)\n",
    "            if \"scalar\" in arrayname_.lower():\n",
    "                ScalarArrayName = arrayname_\n",
    "        cross_section_mean_array.append(np.mean(vtk_to_numpy(inner_section_.GetPointData().GetArray(ScalarArrayName))))\n",
    "    \n",
    "    # add interpolation— then remove the element based on leading/lagging and store it in the dict\n",
    "    print(len(cross_section_mean_array))\n",
    "    tac = np.empty(2*len(cross_section_mean_array) - 1)\n",
    "    for i in range(len(cross_section_mean_array) - 1):\n",
    "        tac[2*i] = cross_section_mean_array[i]\n",
    "        tac[2*i+1] = (cross_section_mean_array[i] + cross_section_mean_array[i+1])/2\n",
    "    \n",
    "    tac[-1] = cross_section_mean_array[-1]\n",
    "    print(len(tac))\n",
    "\n",
    "    LowerMeanArrays[cumulative_distance[len(centerline_upper_points) + idx]] = tac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is there any algorithm for UPSLOPE DETECTION?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(LowerMesh.keys()))\n",
    "print(len(LowerMeanArrays[list(LowerMeanArrays.keys())[0]]))\n",
    "print(len(indeces_u), len(indeces_l))\n",
    "print(len(UpperMeanArrays), len(LowerMeanArrays))\n",
    "\n",
    "print(indeces_u)\n",
    "print(indeces_l)\n",
    "keys = [cumulative_distance[len(centerline_upper_points) + idx] for idx in indeces_l]\n",
    "print(keys, len(set(keys)), len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_time = 11 # the time point when the spatial attenuation is extracted.\n",
    "\n",
    "SpatialArray = []\n",
    "SamplingLocation = list(UpperMeanArrays.keys()) + list(LowerMeanArrays.keys())\n",
    "for key, array in UpperMeanArrays.items():\n",
    "    SpatialArray.append(array[sample_time])\n",
    "for key, array in LowerMeanArrays.items():\n",
    "    SpatialArray.append(array[sample_time - 1 ])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(SamplingLocation, SpatialArray, marker = 'o', s = 100, label = \"Centerline Attenuation\")\n",
    "x_fit = np.linspace(min(SamplingLocation), max(SamplingLocation), 100).reshape(-1,1)\n",
    "slope_s, intercept, _, _, _ = linregress(SamplingLocation, SpatialArray)\n",
    "y_fit = slope_s * x_fit + intercept\n",
    "plt.plot(x_fit, y_fit, 'r-', linewidth=2, label= f\"Trend Line, slope ={int(slope_s*100)/100}\")\n",
    "plt.ylim([300, 800])\n",
    "plt.xlabel(\"Distance from the inlet (mm)\", size = 16)\n",
    "plt.ylabel(\"Attenuation (HU)\", size = 16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upslope_begins = 8\n",
    "upslope_ends = 13\n",
    "\n",
    "heart_rate = 75 #beats per minutes\n",
    "beat_duration = 60/heart_rate\n",
    "\n",
    "array = UpperMeanArrays[list(UpperMeanArrays.keys())[0]]\n",
    "\n",
    "Upslope = array[upslope_begins:upslope_ends]\n",
    "count = [i * beat_duration for i in range(len(array))]\n",
    "count_upslope = [i * beat_duration for i in range(upslope_begins, upslope_ends)]\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(count, array, marker = 'o', s = 100, label = \"Centerline Attenuation\")\n",
    "t_fit = np.linspace(min(count_upslope), max(count_upslope), 100).reshape(-1,1)\n",
    "slope_t, intercept, _, _, _ = linregress(count_upslope, Upslope)\n",
    "y_fit_t = slope_t * t_fit + intercept\n",
    "plt.plot(t_fit, y_fit_t, 'r-', linewidth=2, label= f\"Trend Line, slope ={int(slope_t*100)/100}\")\n",
    "plt.xlabel(\"time (s)\", size = 16)\n",
    "plt.ylabel(\"Attenuation (HU)\", size = 16)\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity = abs(slope_t/slope_s)\n",
    "flow_rate = velocity*Area/1000*60\n",
    "\n",
    "print(velocity/10, \"cm/s\")\n",
    "print(Area, \"mm^2\")\n",
    "print(flow_rate, \"mL/min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo:\n",
    "\n",
    " ~~- Verify the interpolation and concatenation~~\n",
    "\n",
    " ~~- IMPLEMENT the BAYSIAN FRAMEWORK~~: **Theoretical work is done: implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Velocity Estimation Using Adaptive Filtering of the Advection Diffusion Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination of the adaptive filters and modelling:\n",
    " 1) Baysian theorem: we assume that the system noise is a Guassian noise.\n",
    "    \n",
    "    $$ noise \\ \\alpha \\ e^(\\frac{m^2}{\\sigma^2}) $$\n",
    "\n",
    "    where $m$ is the mean and $\\sigma$ is the standard diviation.\n",
    "\n",
    "    $$ m = \\sum \\sqrt(C_{measured}^2 - C_{model}^2) $$\n",
    "\n",
    "    where C is the contrast dispersion measured from the vessel or modeled by the Advection-Dissusion equation. In this context m is the Mean Squared Error ($MSE$).\n",
    "    From a Baysian perspective, the velocity with maximum probability is what maximizes the likelihood of our observation. So, the velocity that is most probable is the velocity that minimizes $MSE$.\n",
    "\n",
    " 2) Steps to implement the concept of adaptive filter on the velocity estimation:\n",
    "\n",
    "   - Estimate velocity from inverse advection diffusion:\n",
    "\n",
    "   $$ v_0 \\ = \\ -\\frac{\\frac{\\partial C}{\\partial t}}{\\frac{\\partial C}{\\partial x}} $$\n",
    "\n",
    "   - Solve ODE assuming that $\\frac{\\partial C}{\\partial t}$ is constant:\n",
    "\n",
    "   $$ D\\frac{\\partial^2 C_n}{\\partial x^2} - v_n \\frac{\\partial C_n}{\\partial x} - Slope_t $$\n",
    "\n",
    "   - Find $MSE$.\n",
    "\n",
    "   - Update velocity:\n",
    "\n",
    "   $$ v_{n+1} = v_n + \\mu.E.\\frac{\\partial C}{\\partial x} $$\n",
    "\n",
    "   - Repeat until convergance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1: ODE solver\n",
    "\n",
    "$$ D \\ddot C - v \\dot C - slope_t = 0 $$\n",
    "$$ z = \\dot C $$\n",
    "$$ D \\dot z - vz - slope_t = 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dSdx(t, S, v, slope_t):\n",
    "    z, C = S\n",
    "    return [C, (v*z + slope_t)/0.04] # D = 0.04\n",
    "\n",
    "\n",
    "S_0 = [slope_s, y_fit[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(slope_s)\n",
    "print(y_fit[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fit.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = odeint(dSdx, y0=S_0, t=x_fit.T[0], tfirst=True, args = (velocity, slope_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_sol = sol.T[1]\n",
    "C_sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are way off so the best way is to solve for C analytically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume diffusion force is zero for simplicity. Then, the problem changes into solving the following PDE for $C(t,x)$:\n",
    "\n",
    "$$ \\frac{\\partial C}{\\partial t} = -v \\frac{\\partial C}{\\partial x} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**todo:**\n",
    "Implement a Fenics pipeline here to solve for the above PDE. OR solve teh pde with FFT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waterfall plot of the TAC along the vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.array(count)))\n",
    "print(len(UpperMeanArrays[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.array(list(UpperMeanArrays.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**todo:**\n",
    "Add phase shift calculation to the for-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UpperMeanArrays2 = {}\n",
    "array = UpperMeanArrays[0]\n",
    "count = [i * beat_duration for i in range(len(array)+1)]\n",
    "time = np.linspace(min(count), max(count), 100)\n",
    "for key, arr in UpperMeanArrays.items():\n",
    "    arr_zero_pad = np.zeros((arr.shape[0] + 1,))\n",
    "    if leading:\n",
    "        arr_zero_pad[1:] = arr\n",
    "    else:\n",
    "        arr_zero_pad[:-1] = arr\n",
    "    cs = CubicSpline(count, arr_zero_pad)\n",
    "    UpperMeanArrays2[key] = cs(time)\n",
    "\n",
    "LowerMeanArrays2 = {}\n",
    "for key, arr in LowerMeanArrays.items():\n",
    "    arr_zero_pad = np.zeros((arr.shape[0] + 1,))\n",
    "    if leading:\n",
    "        arr_zero_pad[:-1] = arr\n",
    "    else:\n",
    "        arr_zero_pad[1:] = arr\n",
    "    cs = CubicSpline(count, arr_zero_pad)\n",
    "    LowerMeanArrays2[key] = cs(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(facecolor=\"black\")\n",
    "ax = fig.add_subplot(111, projection='3d', facecolor = \"black\")\n",
    "plt.set_cmap('jet_r')\n",
    "L = np.array(list(UpperMeanArrays.keys()))\n",
    "step = len(L) // 7\n",
    "x = L[::step][:7]\n",
    "for j, l in enumerate(x):\n",
    "    arr = UpperMeanArrays2[l]\n",
    "    x_ = l*np.ones(len(arr))\n",
    "    ax.plot(time, x_, arr, color = cm.jet(j*30))\n",
    "\n",
    "L2 = np.array(list(LowerMeanArrays.keys()))\n",
    "step = len(L2) // 3\n",
    "x = L2[::step][:3]\n",
    "for j, l in enumerate(x):\n",
    "    arr = LowerMeanArrays2[l]\n",
    "    x_ = l*np.ones(len(arr))\n",
    "    ax.plot(time, x_, arr, color = cm.jet((j+7)*30))\n",
    "\n",
    "ax.set_xlabel(\"time (s)\")\n",
    "ax.set_ylabel(\"Length (mm)\")\n",
    "ax.tick_params(colors=\"white\")\n",
    "ax.xaxis.label.set_color(\"white\")\n",
    "ax.yaxis.label.set_color(\"white\")\n",
    "ax.zaxis.label.set_color(\"white\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = np.stack([arr for _, arr in UpperMeanArrays2.items()])\n",
    "C2 = np.stack([arr for _, arr in LowerMeanArrays2.items()])\n",
    "print(C1.shape)\n",
    "print(C2.shape)\n",
    "C = np.vstack([C1, C2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.flipud(C), aspect=\"auto\", extent=[time.min(), time.max(), L.min(), L2.max()], cmap='jet')\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.ylabel(\"Length (mm)\")\n",
    "plt.colorbar(label=\"Intensity (HU)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_idx = 14 #14 was selected manually and is the time were the decay starts\n",
    "UpperMeanArrays2 = {}\n",
    "array = UpperMeanArrays[0][decay_idx:] \n",
    "print(array.shape)\n",
    "count = [i * beat_duration for i in range(len(array))]\n",
    "time = np.linspace(min(count), max(count), 100)\n",
    "for key, arr in UpperMeanArrays.items():\n",
    "    arr_ = arr[decay_idx:]\n",
    "    cs = CubicSpline(count, arr_)\n",
    "    UpperMeanArrays2[key] = cs(time)\n",
    "\n",
    "LowerMeanArrays2 = {}\n",
    "for key, arr in LowerMeanArrays.items():\n",
    "    arr_zero_pad = np.zeros((arr.shape[0] + 1,))\n",
    "    arr_ = arr[decay_idx-1:-1]\n",
    "    cs = CubicSpline(count, arr_)\n",
    "    LowerMeanArrays2[key] = cs(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(facecolor=\"black\")\n",
    "ax = fig.add_subplot(111, projection='3d', facecolor = \"black\")\n",
    "plt.set_cmap('jet_r')\n",
    "L = np.array(list(UpperMeanArrays.keys()))\n",
    "step = len(L) // 7\n",
    "x = L[::step][:7]\n",
    "for j, l in enumerate(x):\n",
    "    arr = UpperMeanArrays2[l]\n",
    "    x_ = l*np.ones(len(arr))\n",
    "    ax.plot(time, x_, arr, color = cm.jet(j*30))\n",
    "\n",
    "L2 = np.array(list(LowerMeanArrays.keys()))\n",
    "step = len(L2) // 3\n",
    "x = L2[::step][:3]\n",
    "for j, l in enumerate(x):\n",
    "    arr = LowerMeanArrays2[l]\n",
    "    x_ = l*np.ones(len(arr))\n",
    "    ax.plot(time, x_, arr, color = cm.jet((j+7)*30))\n",
    "\n",
    "ax.set_xlabel(\"time (s)\")\n",
    "ax.set_ylabel(\"Length (mm)\")\n",
    "ax.set_zlabel(\"Intensity (HU)\")\n",
    "ax.tick_params(colors=\"white\")\n",
    "ax.xaxis.label.set_color(\"white\")\n",
    "ax.yaxis.label.set_color(\"white\")\n",
    "ax.zaxis.label.set_color(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = np.stack([arr for _, arr in UpperMeanArrays2.items()])\n",
    "C2 = np.stack([arr for _, arr in LowerMeanArrays2.items()])\n",
    "print(C1.shape)\n",
    "print(C2.shape)\n",
    "C = np.vstack([C1, C2])\n",
    "\n",
    "\n",
    "n_old, _ = C.shape\n",
    "x_old = np.linspace(L.min(), L2.max(), n_old)\n",
    "x_new = np.linspace(L.min(), L2.max(), 100)\n",
    "\n",
    "\n",
    "f = interp1d(x_old, C, kind=\"cubic\", axis=0)\n",
    "C_interp = f(x_new)\n",
    "C_interp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.flipud(C_interp), aspect=\"auto\", extent=[time.min(), time.max(), L.min(), L2.max()], cmap='jet')\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.ylabel(\"Length (mm)\")\n",
    "plt.colorbar(label=\"Intensity (HU)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(facecolor=\"black\")\n",
    "ax = fig.add_subplot(111, projection='3d', facecolor = \"black\")\n",
    "plt.set_cmap('jet_r')\n",
    "step = len(time) // 10\n",
    "time_ = np.array(time)[::step][:10]\n",
    "idx = [np.where(time == i)[0][0] for i in time_]\n",
    "for j, l in enumerate(idx):\n",
    "    arr = C_interp[:,l]\n",
    "    t_ = time_[j]*np.ones(len(arr))\n",
    "    ax.plot(t_, x_new, arr, color = cm.jet((len(idx)-j)*30))\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"time (s)\")\n",
    "ax.set_ylabel(\"Length (mm)\")\n",
    "ax.tick_params(colors=\"white\")\n",
    "ax.xaxis.label.set_color(\"white\")\n",
    "ax.yaxis.label.set_color(\"white\")\n",
    "ax.zaxis.label.set_color(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-adding\n",
    "\n",
    "original_array = np.array([[1, 2, 3],\n",
    "                           [4, 5, 6],\n",
    "                           [7, 8, 9]])\n",
    "\n",
    "np.pad(original_array, pad_width=((0, 0), (2, 2)))\n",
    "\n",
    "\n",
    "C_interp2 = np.pad(C_interp, pad_width=((100, 100), (0, 0)))\n",
    "x_new.shape\n",
    "\n",
    "Length = x_new.max() - x_new.min() #Length of domain\n",
    "N = x_new.shape[0] #number of points along the x\n",
    "dx = Length/(N - 1)\n",
    "x_new2 = np.array([i*dx for i in range(len(C_interp2))])\n",
    "\n",
    "C_interp2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Length = x_new.max() - x_new.min() #Length of domain\n",
    "N = x_new.shape[0] #number of points along the x\n",
    "dx = Length/(N - 1) #spatial differences\n",
    "kappa = 2*np.pi*np.fft.fftfreq(N, dx)\n",
    "\n",
    "D = 0.4 #diffusion coefficient\n",
    "\n",
    "C0 = C_interp[:,0] #Contrast dispersion at the time of zero along the vessel\n",
    "#C0 = np.zeros_like(x_new)\n",
    "#C0[int((Length/2 - Length/10)/dx):int((Length/2 + Length/10)/dx)] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "C0hat = np.fft.fft(C0)\n",
    "C0hat_ri = np.concatenate((C0hat.real, C0hat.imag))\n",
    "\n",
    "\n",
    "\n",
    "# Implementing the diffusion part in frequency domain\n",
    "def Diffusion(Chat_ri, t, kappa, D, v, k):\n",
    "    Chat = Chat_ri[:N] + (1j) * Chat_ri[N:]\n",
    "    d_Chat = - D * (np.power(kappa, 2)) * Chat - (1 - np.exp(-k * t)) * Chat #- 1j * v * kappa* Chat \n",
    "    d_Chat_ri = np.concatenate((d_Chat.real, d_Chat.imag)).astype('float64')\n",
    "    return d_Chat_ri\n",
    "\n",
    "Chat_ri = odeint(Diffusion, C0hat_ri, time, args=(kappa,D, 100, 0.25)) # k is for the exponential decay and was selected by trial and error.\n",
    "\n",
    "Chat = Chat_ri[:,:N] + (1j) * Chat_ri[:,N:]\n",
    "\n",
    "C_Gaussian_filter = np.zeros_like(Chat)\n",
    "for i in range(len(time)):\n",
    "    C_Gaussian_filter[i,:] = np.fft.ifft(Chat[i,:])\n",
    "\n",
    "C_Gaussian_filter = C_Gaussian_filter.real\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(facecolor=\"black\")\n",
    "ax = fig.add_subplot(111, projection='3d', facecolor = \"black\")\n",
    "plt.set_cmap('jet_r')\n",
    "c_plot = C_Gaussian_filter[0:-1:10,:]\n",
    "for k in range(c_plot.shape[0]):\n",
    "    ys = k*np.ones(c_plot.shape[1])\n",
    "    ax.plot(ys,x_new,c_plot[k,:], color = cm.jet(k*30))\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"time (s)\")\n",
    "ax.set_ylabel(\"Length (mm)\")\n",
    "ax.tick_params(colors=\"white\")\n",
    "ax.xaxis.label.set_color(\"white\")\n",
    "ax.yaxis.label.set_color(\"white\")\n",
    "ax.zaxis.label.set_color(\"white\")\n",
    "ax.set_zbound([100, 800])\n",
    "\n",
    "\n",
    "fig = plt.figure(facecolor=\"black\")\n",
    "ax = fig.add_subplot(111, projection='3d', facecolor = \"black\")\n",
    "plt.set_cmap('jet_r')\n",
    "c_plot = C_Gaussian_filter[:,0:-1:10]\n",
    "for k in range(c_plot.shape[1]):\n",
    "    ys = x_new[k]*np.ones(c_plot.shape[0])\n",
    "    ax.plot(time,ys,c_plot[:,k], color = cm.jet(k*30))\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"time (s)\")\n",
    "ax.set_ylabel(\"Length (mm)\")\n",
    "ax.tick_params(colors=\"white\")\n",
    "ax.xaxis.label.set_color(\"white\")\n",
    "ax.yaxis.label.set_color(\"white\")\n",
    "ax.zaxis.label.set_color(\"white\")\n",
    "ax.set_zbound([100, 800])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt = (time.max()-time.min())/(len(time)-1)\n",
    "Velocity = []\n",
    "for t1 in range(1,len(time)):\n",
    "    C0 = C_Gaussian_filter[t1,:]\n",
    "    C1 = C_interp[t1,:]\n",
    "\n",
    "    cross_corr = np.correlate(C0 , C1 , mode='full')\n",
    "    idx = np.argmax(cross_corr)\n",
    "    lag_sample = idx - (N//2)\n",
    "    delta_x = lag_sample * dx\n",
    "    velocity = delta_x/dt\n",
    "    Velocity.append(velocity/10)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(time[1:], Velocity)\n",
    "plt.ylabel(\"Velocity (cm/s)\")\n",
    "plt.xlabel(\"time (s)\")\n",
    "\n",
    "print(Velocity[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtkfenics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
